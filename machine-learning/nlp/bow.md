# 词袋模型BoW

词袋(Bag Of Word)模型是最早的以词语为基本处理单元的文本向量化方法。  
它相当于一个词袋，不考虑词/句之间的相关性，只要出现了该词，就会记为1，再次出现就会+1。  
>比如对于这句话：  
John likes to watch movies,Mary likes too.  
John also likes to watch football games.  
基于上述两个文档中出现的单词,构建如下词典:  
"John":1,"likes":2,"to":3,"watch":4,"movies":5,"also":6,"football":7,"games":8,"Mary":9,"too":10  
用one-hot可以表示为：  
John:[1,0,0,0,0,0,0,0,0,0]  
likes:[0,1,0,0,0,0,0,0,0,0]  
...  
too:[0,0,0,0,0,0,0,0,0,1]  
上面的词典中包含10个单词, 每个单词有唯一的索引, 那么每个文本我们可以使用一个10维的向量来表示。如下：  
       [1, 2, 1, 1, 1, 0, 0, 0, 1, 1]  
       [1, 1,1, 1, 0, 1, 1, 1, 0, 0]  
该向量与原来文本中单词出现的顺序没有关系，而是词典中每个单词在文本中出现的频率。

词袋模型方法虽然简单易行,但是存在如下三方面的问题:  
* 维度灾难。如果上述例子词典中包含10000个单词,那么每个
文本需要用10000维的向量表示.
* 无法保留词序信息。
* 存在语义鸿沟的问题。